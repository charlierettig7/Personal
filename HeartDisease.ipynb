{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlierettig7/Personal/blob/master/HeartDisease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bzjXCK93WFRu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pylab as pl\n",
        "import sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U33C-Ie1WFRw",
        "outputId": "7fa7e83d-0848-40e1-8d4a-c67edd1bfc47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ucimlrepo'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3f534ad24780>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mucimlrepo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_ucirepo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# fetch dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mheart_disease\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_ucirepo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ucimlrepo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "Features = heart_disease.data.features\n",
        "Target = heart_disease.data.targets\n",
        "\n",
        "Xdf = pd.DataFrame(Features)\n",
        "ydf = pd.DataFrame(Target)\n",
        "full_data = pd.concat([Xdf,ydf], axis = 1)\n",
        "\n",
        "# Drop rows with any NaN values\n",
        "full_data = full_data.dropna()\n",
        "\n",
        "\n",
        "# metadata\n",
        "print(heart_disease.metadata)\n",
        "\n",
        "# variable information\n",
        "print(heart_disease.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DFMCQqDWFRw"
      },
      "outputs": [],
      "source": [
        "#Exploratory\n",
        "print(full_data.head())\n",
        "print(full_data.shape)\n",
        "print(full_data['num'].unique())\n",
        "print(full_data.groupby('num').size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W24wflW7WFRx"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='num', data=full_data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQZieVkNWFRx"
      },
      "outputs": [],
      "source": [
        "full_data.drop('num', axis=1).plot(kind='box', subplots=True, layout=(5,3), sharex=False, sharey=False, figsize=(9,9),\n",
        "title='Box Plot for each input variable')\n",
        "plt.savefig('Heart_full')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGjc_ipeWFRx"
      },
      "outputs": [],
      "source": [
        "full_data.drop('num' ,axis=1).hist(bins=30, figsize=(9,9))\n",
        "pl.suptitle(\"Histogram for each numeric input variable\")\n",
        "plt.savefig('Heart_full_hist')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWxIRyCxWFRx"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feature_names = list(Xdf.columns.values)\n",
        "\n",
        "X = full_data[feature_names]\n",
        "y = full_data['num']\n",
        "\n",
        "# Set up the colormap\n",
        "cmap = cm.get_cmap('gnuplot')\n",
        "\n",
        "# Create the scatter matrix and pass the color values directly within plt.scatter\n",
        "scatter = scatter_matrix(X, marker='o', s=40, hist_kwds={'bins': 15}, figsize=(9, 9), diagonal='hist')\n",
        "\n",
        "# Add color to each plot\n",
        "for i, ax in enumerate(scatter.ravel()):\n",
        "    row, col = divmod(i, len(X.columns))\n",
        "    if row != col:  # Avoid coloring the histogram diagonals\n",
        "        colors = cmap(y / y.max())  # Normalize y for colormap\n",
        "        ax.scatter(X.iloc[:, col], X.iloc[:, row], c=colors, marker='o', s=10)\n",
        "\n",
        "plt.suptitle('Scatter-matrix for each input variable')\n",
        "plt.savefig('heart_scatter_matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Do3fXqAWFRx"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feature_names = list(Xdf.columns.values)\n",
        "\n",
        "X = full_data[feature_names]\n",
        "y2 = np.where(full_data['num'] != 0, 1, 0)\n",
        "\n",
        "# Set up the colormap\n",
        "cmap = cm.get_cmap('gnuplot')\n",
        "\n",
        "# Create the scatter matrix and pass the color values directly within plt.scatter\n",
        "scatter = scatter_matrix(X, marker='o', s=40, hist_kwds={'bins': 15}, figsize=(9, 9), diagonal='hist')\n",
        "\n",
        "# Add color to each plot\n",
        "for i, ax in enumerate(scatter.ravel()):\n",
        "    row, col = divmod(i, len(X.columns))\n",
        "    if row != col:  # Avoid coloring the histogram diagonals\n",
        "        colors = cmap(y / y.max())  # Normalize y for colormap\n",
        "        ax.scatter(X.iloc[:, col], X.iloc[:, row], c=colors, marker='o', s=10)\n",
        "\n",
        "plt.suptitle('Scatter-matrix for each input variable')\n",
        "plt.savefig('heart_scatter_matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdfaPTlHWFRy"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "corr_matrix = full_data.corr()\n",
        "\n",
        "# Set up the figure\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Draw the heatmap with a color map and annotating the correlations\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, cbar=True, linewidths=0.5)\n",
        "\n",
        "# Add a title\n",
        "plt.title(\"Correlation Heatmap of Variables\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8FGGq_GWFRy"
      },
      "outputs": [],
      "source": [
        "# Generate the pairplot\n",
        "sns.pairplot(full_data, hue='num', palette='viridis', markers=[\"o\", \"s\", \"D\"])\n",
        "\n",
        "# Add a title (PairPlot doesn't have a direct way to set titles, so using plt.title won't apply to each subplot)\n",
        "plt.suptitle(\"Pairplot of Features Colored by Target Variable\", y=1.02)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03UbFrt7WFRy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get the summary statistics\n",
        "desc_stats = X.describe()\n",
        "\n",
        "# Plot each feature's summary statistics\n",
        "for column in desc_stats.columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(desc_stats.index, desc_stats[column], color=\"skyblue\")\n",
        "    plt.title(f'Summary Statistics for {column}')\n",
        "    plt.xlabel('Statistic')\n",
        "    plt.ylabel('Value')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGH792NJWFRy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EDGN63HWFRy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, random_state=0)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7E9SNbgWFRz"
      },
      "source": [
        "Multiclass KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjbrMKW9WFRz"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
        ".format(knn.score(X_train, y_train)))\n",
        "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
        ".format(knn.score(X_test, y_test)))\n",
        "\n",
        "print(knn.get_params())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwIgDcmFWFR0"
      },
      "source": [
        "Single-Class KNN below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqEZRqNxWFR0"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn2 = KNeighborsClassifier()\n",
        "\n",
        "knn2.fit(X_train, y2_train)\n",
        "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
        ".format(knn2.score(X_train, y2_train)))\n",
        "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
        ".format(knn2.score(X_test, y2_test)))\n",
        "\n",
        "print(knn2.get_params())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP6-GisdWFR0"
      },
      "source": [
        "Multiclass Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TT7GGjLWFR0"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "print('Accuracy of Decision Tree classifier on training set: {:.2f}' .format(clf.score(X_train, y_train)))\n",
        "print('Accuracy of Decision Tree classifier on test set: {:.2f}' .format(clf.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYOb9Xf8WFR0"
      },
      "source": [
        "Single Class Decision Tree below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afkK7caYWFR0"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf2 = DecisionTreeClassifier().fit(X_train, y2_train)\n",
        "print('Accuracy of Decision Tree classifier on training set: {:.2f}' .format(clf2.score(X_train, y2_train)))\n",
        "print('Accuracy of Decision Tree classifier on test set: {:.2f}' .format(clf2.score(X_test, y2_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdFvjVghWFR0"
      },
      "source": [
        "Multi-Class LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiSYURFrWFR1"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "print('Accuracy of LDA classifier on training set: {:.2f}' .format(lda.score(X_train, y_train)))\n",
        "print('Accuracy of LDA classifier on test set: {:.2f}' .format(lda.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKxMA9k7WFR1"
      },
      "source": [
        "Binary LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyoMQo7ZWFR1"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda2 = LinearDiscriminantAnalysis()\n",
        "lda2.fit(X_train, y2_train)\n",
        "print('Accuracy of LDA classifier on training set: {:.2f}' .format(lda2.score(X_train, y2_train)))\n",
        "print('Accuracy of LDA classifier on test set: {:.2f}' .format(lda2.score(X_test, y2_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvRmFKTqWFR1"
      },
      "source": [
        "Multiclass SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyDonveeWFR1"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
        ".format(svm.score(X_train, y_train)))\n",
        "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
        ".format(svm.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxpPI1FnWFR1"
      },
      "source": [
        "Binary SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvIIJ4ySWFR1"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svm2 = SVC()\n",
        "svm2.fit(X_train, y2_train)\n",
        "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
        ".format(svm2.score(X_train, y2_train)))\n",
        "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
        ".format(svm2.score(X_test, y2_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7NyCgnpWFR1"
      },
      "outputs": [],
      "source": [
        "\n",
        "pred_KNN = knn.predict(X_test)\n",
        "pred_LDA = lda.predict(X_test)\n",
        "pred_SVM = svm.predict(X_test)\n",
        "\n",
        "\n",
        "pred_KNN_bi = knn2.predict(X_test)\n",
        "pred_LDA_bi = lda2.predict(X_test)\n",
        "pred_SVM_bi = svm2.predict(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KscOA9YaWFR2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate metrics for multiclass classifiers\n",
        "def get_multiclass_metrics(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Sensitivity (Recall for each class and then macro average)\n",
        "    sensitivity = recall_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    # Specificity calculation for each class\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    specificity_per_class = []\n",
        "    for i in range(len(cm)):\n",
        "        # True negatives (sum of elements not in row i or column i)\n",
        "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
        "        # False positives (sum of elements in column i excluding diagonal)\n",
        "        fp = cm[:, i].sum() - cm[i, i]\n",
        "        # Specificity for class i\n",
        "        specificity = tn / (tn + fp)\n",
        "        specificity_per_class.append(specificity)\n",
        "    specificity = np.mean(specificity_per_class)  # Average specificity across classes\n",
        "\n",
        "    return accuracy, sensitivity, specificity\n",
        "\n",
        "##Multiclass\n",
        "\n",
        "# Calculate metrics for each classifier\n",
        "acc_knn, sens_knn, spec_knn = get_multiclass_metrics(y_test, pred_KNN)\n",
        "acc_lda, sens_lda, spec_lda = get_multiclass_metrics(y_test, pred_LDA)\n",
        "acc_svm, sens_svm, spec_svm = get_multiclass_metrics(y_test, pred_SVM)\n",
        "\n",
        "# Prepare data for grouped bar chart\n",
        "classifiers = ['KNN', 'LDA', 'SVM']\n",
        "accuracy = [acc_knn, acc_lda, acc_svm]\n",
        "sensitivity = [sens_knn, sens_lda, sens_svm]\n",
        "specificity = [spec_knn, spec_lda, spec_svm]\n",
        "\n",
        "# Set up the bar chart\n",
        "metrics = ['Accuracy', 'Sensitivity', 'Specificity']\n",
        "data = [accuracy, sensitivity, specificity]\n",
        "\n",
        "x = np.arange(len(classifiers))  # Label locations\n",
        "bar_width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot each metric\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax.bar(x + i * bar_width, data[i], width=bar_width, label=metric)\n",
        "\n",
        "# Add labels and titles\n",
        "ax.set_xlabel('Classifier')\n",
        "ax.set_ylabel('Metric Score')\n",
        "ax.set_title('Performance Comparison of KNN, LDA, and SVM (Multiclass)')\n",
        "ax.set_xticks(x + bar_width)\n",
        "ax.set_xticklabels(classifiers)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Confusion Matrix KNN\")\n",
        "print(confusion_matrix(y_test, pred_KNN))\n",
        "print(\"Confusion Matrix LDA\")\n",
        "print(confusion_matrix(y_test, pred_LDA))\n",
        "print(\"Confusion Matrix SVM\")\n",
        "print(confusion_matrix(y_test, pred_SVM))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMGbYuCxWFR2"
      },
      "outputs": [],
      "source": [
        "##Single Class\n",
        "\n",
        "# Calculate metrics for each classifier\n",
        "acc_knn, sens_knn, spec_knn = get_multiclass_metrics(y2_test, pred_KNN_bi)\n",
        "acc_lda, sens_lda, spec_lda = get_multiclass_metrics(y2_test, pred_LDA_bi)\n",
        "acc_svm, sens_svm, spec_svm = get_multiclass_metrics(y2_test, pred_SVM_bi)\n",
        "\n",
        "# Prepare data for grouped bar chart\n",
        "classifiers = ['KNN', 'LDA', 'SVM']\n",
        "accuracy = [acc_knn, acc_lda, acc_svm]\n",
        "sensitivity = [sens_knn, sens_lda, sens_svm]\n",
        "specificity = [spec_knn, spec_lda, spec_svm]\n",
        "\n",
        "# Set up the bar chart\n",
        "metrics = ['Accuracy', 'Sensitivity', 'Specificity']\n",
        "data = [accuracy, sensitivity, specificity]\n",
        "\n",
        "x = np.arange(len(classifiers))  # Label locations\n",
        "bar_width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot each metric\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax.bar(x + i * bar_width, data[i], width=bar_width, label=metric)\n",
        "\n",
        "# Add labels and titles\n",
        "ax.set_xlabel('Classifier')\n",
        "ax.set_ylabel('Metric Score')\n",
        "ax.set_title('Performance Comparison of KNN, LDA, and SVM (Multiclass)')\n",
        "ax.set_xticks(x + bar_width)\n",
        "ax.set_xticklabels(classifiers)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Confusion Matrix KNN\")\n",
        "print(confusion_matrix(y_test, pred_KNN))\n",
        "print(\"Confusion Matrix LDA\")\n",
        "print(confusion_matrix(y_test, pred_LDA))\n",
        "print(\"Confusion Matrix SVM\")\n",
        "print(confusion_matrix(y_test, pred_SVM))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZIDii2kWFR2"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming you already have the confusion matrices for each classifier\n",
        "cm_knn = confusion_matrix(y_test, pred_KNN)\n",
        "cm_lda = confusion_matrix(y_test, pred_LDA)\n",
        "cm_svm = confusion_matrix(y_test, pred_SVM)\n",
        "\n",
        "# Plotting function\n",
        "def plot_confusion_matrix(cm, title='Confusion Matrix'):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrix for each classifier\n",
        "plot_confusion_matrix(cm_knn, title='Confusion Matrix for KNN')\n",
        "plot_confusion_matrix(cm_lda, title='Confusion Matrix for LDA')\n",
        "plot_confusion_matrix(cm_svm, title='Confusion Matrix for SVM')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4ZqdAoPWFR2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming you already have the confusion matrices for each classifier\n",
        "cm_knn = confusion_matrix(y2_test, pred_KNN_bi)\n",
        "cm_lda = confusion_matrix(y2_test, pred_LDA_bi)\n",
        "cm_svm = confusion_matrix(y2_test, pred_SVM_bi)\n",
        "\n",
        "# Plotting function\n",
        "def plot_confusion_matrix(cm, title='Confusion Matrix'):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrix for each classifier\n",
        "plot_confusion_matrix(cm_knn, title='Confusion Matrix for KNN')\n",
        "plot_confusion_matrix(cm_lda, title='Confusion Matrix for LDA')\n",
        "plot_confusion_matrix(cm_svm, title='Confusion Matrix for SVM')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "\n",
        "\n",
        "def roc_curver_2D_better(variation):\n",
        "    frame = inspect.currentframe().f_back\n",
        "    title = [name for name, val in frame.f_locals.items() if val is variation] #gets name\n",
        "    # Binarize the true labels\n",
        "    y_test_bin = label_binarize(y_test, classes=[0, 1])\n",
        "    print(\"Classes in the model:\", variation.classes_)\n",
        "\n",
        "    variation_scores = variation.predict_proba(X_test)\n",
        "\n",
        "    y_true = y_test_bin.ravel() #set to 1D\n",
        "    variation_scores = variation_scores.ravel()\n",
        "\n",
        "    # Calculate micro-average ROC curve and AUC\n",
        "    fps, tps, _ = roc_curve(y_true , variation_scores)\n",
        "    roc_auc_micro = auc(fps, tps)\n",
        "\n",
        "    # Plot the Micro-average ROC curve\n",
        "\n",
        "    plt.plot(fps, tps, lw=2, label=f'' + title[0] +' (AUC = ' + str(round(roc_auc_micro, 2)) + ')')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
        "    plt.xlabel('False Positive Percent')\n",
        "    plt.ylabel('True Positive Percent')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.figure()\n",
        "roc_curver_2D_better(lda2)\n",
        "roc_curver_2D_better(knn2)\n",
        "roc_curver_2D_better(clf2)\n",
        "roc_curver_2D_better(svm2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sw7W466DUXeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}